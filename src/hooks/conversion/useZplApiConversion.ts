import { useTranslation } from 'react-i18next';
import { useToast } from '@/components/ui/use-toast';
import { delay } from '@/utils/pdfUtils';
import { parseZplBlocks, countZplLabelsWithLog } from '@/utils/zplUtils';
import { DEFAULT_CONFIG, ProcessingMetricsTracker, ProcessingConfig } from '@/config/processingConfig';

export const useZplApiConversion = () => {
  const { toast } = useToast();
  const { t } = useTranslation();

  const convertZplBlocksToPdfs = async (
    labels: string[],
    onProgress: (progress: number) => void,
    config: ProcessingConfig = DEFAULT_CONFIG
  ): Promise<Blob[]> => {
    const totalStartTime = Date.now();
    
    console.log(`üèÅ Starting conversion of ${labels.length} labels with config:`, config);
    
    // Create batches
    const batches: string[][] = [];
    for (let i = 0; i < labels.length; i += config.labelsPerBatch) {
      batches.push(labels.slice(i, i + config.labelsPerBatch));
    }
    
    console.log(`üì¶ Created ${batches.length} batches of ~${config.labelsPerBatch} labels each`);
    
    const PARALLEL_BATCHES = 2; // Reduced from 3 to avoid rate limits
    const results: (Blob | null)[] = new Array(batches.length).fill(null);
    const failedBatches: number[] = [];
    let completed = 0;

    // Track last error context for metadata enrichment
    let lastErrorContext: { status?: number; body?: string; failureType?: string } = {};

    const processBatch = async (batchLabels: string[], batchIndex: number, maxRetries: number = config.maxRetries, baseDelay: number = config.delayBetweenBatches): Promise<Blob | null> => {
      let retryCount = 0;
      
      while (retryCount < maxRetries) {
        try {
          const blockZPL = batchLabels.join('');

          // Explicit timeout with AbortController (30s)
          const controller = new AbortController();
          const timeoutId = setTimeout(() => controller.abort(), 30000);

          const response = await fetch('https://api.labelary.com/v1/printers/8dpmm/labels/4x6/', {
            method: 'POST',
            headers: {
              'Accept': 'application/pdf',
              'Content-Type': 'application/x-www-form-urlencoded',
            },
            body: blockZPL,
            signal: controller.signal,
          });

          clearTimeout(timeoutId);

          if (response.status === 429) {
            retryCount++;
            const waitTime = config.fallbackDelay * retryCount;
            console.log(`‚è≥ Rate limited on batch ${batchIndex + 1}, waiting ${waitTime}ms...`);
            lastErrorContext = { status: 429, body: 'Rate limit exceeded', failureType: 'rate_limit' };
            await delay(waitTime);
            continue;
          }

          if (!response.ok) {
            const errorBody = await response.text().catch(() => 'Could not read body');
            lastErrorContext = { status: response.status, body: errorBody.substring(0, 200), failureType: 'http_error' };
            throw new Error(`HTTP ${response.status}: ${errorBody.substring(0, 200)}`);
          }

          const blob = await response.blob();
          
          if (blob.size === 0) {
            throw new Error('Empty PDF received');
          }
          
          console.log(`‚úÖ Batch ${batchIndex + 1}/${batches.length} completed (${blob.size} bytes)`);
          return blob;
          
        } catch (error) {
          retryCount++;
          
          // Classify error type
          if (error instanceof DOMException && error.name === 'AbortError') {
            lastErrorContext = { failureType: 'timeout', body: 'Request timed out after 30s' };
            console.error(`‚è∞ Batch ${batchIndex + 1} attempt ${retryCount} timed out`);
          } else if (!lastErrorContext.failureType || lastErrorContext.failureType === 'rate_limit') {
            // Network error (no response received)
            if (error instanceof TypeError) {
              lastErrorContext = { failureType: 'network_error', body: error.message?.substring(0, 200) };
            }
            console.error(`‚ùå Batch ${batchIndex + 1} attempt ${retryCount} failed:`, error);
          } else {
            console.error(`‚ùå Batch ${batchIndex + 1} attempt ${retryCount} failed:`, error);
          }
          
          if (retryCount < maxRetries) {
            await delay(baseDelay * retryCount);
          }
        }
      }
      
      return null;
    };

    // Process batches in parallel groups
    for (let i = 0; i < batches.length; i += PARALLEL_BATCHES) {
      const parallelBatches = batches.slice(i, i + PARALLEL_BATCHES);
      const startIdx = i;
      
      const batchResults = await Promise.all(
        parallelBatches.map((batch, j) => processBatch(batch, startIdx + j))
      );
      
      batchResults.forEach((result, j) => {
        if (result) {
          results[startIdx + j] = result;
        } else {
          failedBatches.push(startIdx + j);
        }
      });
      
      completed += parallelBatches.length;
      const progressValue = (completed / batches.length) * 90; // Reserve 10% for retry
      onProgress(progressValue);
      
      // Delay between parallel groups
      if (i + PARALLEL_BATCHES < batches.length) {
        await delay(config.delayBetweenBatches);
      }
    }
    
    // Retry failed batches sequentially with longer delays
    if (failedBatches.length > 0) {
      console.log(`üîÑ Retrying ${failedBatches.length} failed batches sequentially...`);
      
      for (const batchIndex of failedBatches) {
        await delay(config.fallbackDelay); // Wait before retry
        
        const result = await processBatch(batches[batchIndex], batchIndex, 3, config.fallbackDelay);
        
        if (result) {
          results[batchIndex] = result;
          console.log(`‚úÖ Batch ${batchIndex + 1} recovered successfully`);
        } else {
          console.error(`üí• Batch ${batchIndex + 1} permanently failed`);
          toast({
            variant: "destructive",
            title: t('blockError'),
            description: t('blockErrorMessage', { block: batchIndex + 1 }),
            duration: 4000,
          });
        }
      }
    }
    
    onProgress(100);
    
    const pdfs = results.filter((pdf): pdf is Blob => pdf !== null);
    const totalTime = Date.now() - totalStartTime;
    
    console.log(`üèÜ Conversion completed in ${totalTime}ms`);
    console.log(`üìä Final: ${pdfs.length}/${batches.length} batches successful, ${labels.length} labels processed`);
    
    if (pdfs.length === 0) {
      const errorWithContext = new Error(`All ${batches.length} batches failed. No PDFs were generated after ${totalTime}ms. Labels attempted: ${labels.length}`);
      (errorWithContext as any).apiContext = lastErrorContext;
      throw errorWithContext;
    }
    
    if (pdfs.length < batches.length) {
      console.warn(`‚ö†Ô∏è Warning: ${batches.length - pdfs.length} batches failed and were not included in the final PDF`);
    }
    
    return pdfs;
  };

  const parseLabelsFromZpl = (zplContent: string) => {
    const labels = parseZplBlocks(zplContent);
    console.log(`üîç parseLabelsFromZpl: Found ${labels.length} blocks in ZPL content`);
    return labels;
  };

  const countLabelsInZpl = (zplContent: string): number => {
    return countZplLabelsWithLog(zplContent, 'useZplApiConversion');
  };

  return {
    convertZplBlocksToPdfs,
    parseLabelsFromZpl,
    countLabelsInZpl
  };
};
